{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%schemas\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "spark = SparkSession.builder.appName(\"test\").master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "|hello|  2|\n",
      "| tony|  5|\n",
      "+-----+---+\n",
      "\n",
      "+-----+\n",
      "| name|\n",
      "+-----+\n",
      "|hello|\n",
      "| tony|\n",
      "+-----+\n",
      "\n",
      "+-----+---+-----+\n",
      "| name|age|age10|\n",
      "+-----+---+-----+\n",
      "|hello|  2|   20|\n",
      "| tony|  5|   50|\n",
      "+-----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sc = spark.sparkContext\n",
    "my_list = [('hello', 2),('tony', 5)]\n",
    "schema = ['name', 'age']\n",
    "rdd = sc.parallelize(my_list)\n",
    "rdd.collect()\n",
    "df = spark.createDataFrame(rdd, schema)\n",
    "df.show()\n",
    "df.select(\"name\").show()\n",
    "df.withColumn(\"age10\", col(\"age\")*10).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%create dataframe from list\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age| name|\n",
      "+---+-----+\n",
      "| 12|Alice|\n",
      "| 14| John|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d = [{\"name\":\"Alice\", \"age\" : 12}, {\"name\":\"John\", \"age\" : 14}]\n",
    "df_d = spark.createDataFrame(d)\n",
    "df_d.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%create from dictionary\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|matt|  2|\n",
      "| ron|  5|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "Person  = Row('name', 'age')\n",
    "my_list2 =  [('matt', 2),('ron', 5)]\n",
    "rdd2 = sc.parallelize(my_list2)\n",
    "person = rdd2.map(lambda rdd2_element: Person(*rdd2_element))\n",
    "df_r = spark.createDataFrame(person).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%create from row object\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[('a', 1), ('a', 1), ('b', 1)]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_text = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"sep\", \";\").option(\"header\", \"true\").load(\"/Users/tech/codes/SparkJourney/data/books.csv\")\n",
    "# df_text.show(10, False)\n",
    "from operator import add\n",
    "my_list_to_be_reduced = [(\"a\", 1), (\"b\", 1), (\"a\", 1)]\n",
    "rdd = sc.parallelize(my_list_to_be_reduced)\n",
    "sorted(rdd.collect())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%create from text file\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[('a', [1, 1]), ('b', [1])]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
    "sorted(rdd.groupByKey().mapValues(list).collect())\n",
    "#\n",
    "# sorted(rdd.groupByKey().mapValues(list).collect())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|fruits|\n",
      "+------+\n",
      "| apple|\n",
      "|banana|\n",
      "| mango|\n",
      "| apple|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a silly test dataframe from Python collections (lists)\n",
    "schema = [\"fruits\"]\n",
    "wordsDF = spark.createDataFrame([(\"apple\",),(\"banana\",),(\"mango\",),(\"apple\",)],schema)\n",
    "wordsDF.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|length|\n",
      "+------+\n",
      "|     5|\n",
      "|     6|\n",
      "|     5|\n",
      "|     5|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import length\n",
    "wordsDF.select(length(\"fruits\").alias(\"length\")).show()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|fruits|count|\n",
      "+------+-----+\n",
      "| apple|    2|\n",
      "| mango|    1|\n",
      "|banana|    1|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordsDF.groupBy(\"fruits\").count().show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------+\n",
      "|sentence                                                                |\n",
      "+------------------------------------------------------------------------+\n",
      "|The Project Gutenberg eBook of Pride and Prejudice, by Jane Austen      |\n",
      "|                                                                        |\n",
      "|This eBook is for the use of anyone anywhere in the United States and   |\n",
      "|most other parts of the world at no cost and with almost no restrictions|\n",
      "|whatsoever. You may copy it, give it away or re-use it under the terms  |\n",
      "|of the Project Gutenberg License included with this eBook or online at  |\n",
      "|www.gutenberg.org. If you are not located in the United States, you     |\n",
      "|will have to check the laws of the country where you are located before |\n",
      "|using this eBook.                                                       |\n",
      "|                                                                        |\n",
      "+------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "booksDF = spark.read.text(\"/Users/tech/codes/SparkJourney/data/PrideandPrejudice.txt\").select(col(\"value\").alias(\"sentence\"))\n",
    "booksDF.show(10, truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               split|\n",
      "+--------------------+\n",
      "|[The, Project, Gu...|\n",
      "|                  []|\n",
      "|[This, eBook, is,...|\n",
      "|[most, other, par...|\n",
      "|[whatsoever., You...|\n",
      "|[of, the, Project...|\n",
      "|[www.gutenberg.or...|\n",
      "|[will, have, to, ...|\n",
      "|[using, this, eBo...|\n",
      "|                  []|\n",
      "|[Title:, Pride, a...|\n",
      "|                  []|\n",
      "|[Author:, Jane, A...|\n",
      "|                  []|\n",
      "|[Release, Date:, ...|\n",
      "+--------------------+\n",
      "only showing top 15 rows\n",
      "\n",
      "+----------+\n",
      "|      word|\n",
      "+----------+\n",
      "|       The|\n",
      "|   Project|\n",
      "| Gutenberg|\n",
      "|     eBook|\n",
      "|        of|\n",
      "|     Pride|\n",
      "|       and|\n",
      "|Prejudice,|\n",
      "|        by|\n",
      "|      Jane|\n",
      "|    Austen|\n",
      "|      This|\n",
      "|     eBook|\n",
      "|        is|\n",
      "|       for|\n",
      "|       the|\n",
      "|       use|\n",
      "|        of|\n",
      "|    anyone|\n",
      "|  anywhere|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "124749\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, explode\n",
    "bookWordsSplitDF = booksDF.select(split(booksDF.sentence, ' ').alias('split'))\n",
    "bookWordsSplitDF.show(15)\n",
    "bookWordsSingleDF = (bookWordsSplitDF.select(explode(bookWordsSplitDF.split).alias('word')))\n",
    "bookWordsDF = bookWordsSingleDF.where(bookWordsSingleDF.word != '')\n",
    "bookWordsDF.show()\n",
    "bookWordsDFCount = bookWordsDF.count()\n",
    "print(bookWordsDFCount)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}