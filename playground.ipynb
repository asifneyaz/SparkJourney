{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4de3c049-885a-4552-a859-b62e48f45761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id| name|\n",
      "+---+-----+\n",
      "|  1|Neyaz|\n",
      "|  2| Nick|\n",
      "|  3| hari|\n",
      "|  4| john|\n",
      "+---+-----+\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    " MySQL injection to Spark, using the Sakila sample database.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "import logging\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Creates a session on a local master\n",
    "spark = SparkSession.builder.appName(\"MySQL to Dataframe using a JDBC Connection\") \\\n",
    "    .master(\"local[*]\").getOrCreate()\n",
    "\n",
    "user = \"root\"\n",
    "password = \"password\"\n",
    "use_ssl=\"false\"\n",
    "mysql_url = \"jdbc:mysql://localhost:3306/testschema\"\n",
    "dbtable = \"acct\"\n",
    "database=\"testschema\"\n",
    "\n",
    "df = spark.read.format(\"jdbc\") \\\n",
    "    .options(url=mysql_url,\n",
    "             database=database,\n",
    "             dbtable=dbtable,\n",
    "             user=user,\n",
    "             password=password) \\\n",
    "    .load()\n",
    "\n",
    "#df = df.orderBy(df.col(\"last_name\"))\n",
    "\n",
    "# Displays the dataframe and some of its metadata\n",
    "df.show(5)\n",
    "df.printSchema()\n",
    "\n",
    "logging.info(\"The dataframe contains {} record(s).\".format(df.count()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fb4b63f-4e2c-4009-b34f-9feeec04f999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id| name|\n",
      "+---+-----+\n",
      "|  1|Neyaz|\n",
      "+---+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7810e0e-b09d-4bfc-a6be-ccd8314291ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aed09c6b-c68b-4022-bdff-093698286e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_schema = \"'hello', STRINGTYPE, '23', INTEGERTYPE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afb376b9-9711-459d-be6a-ba8264af6d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'hello', STRINGTYPE, '23', INTEGERTYPE\n"
     ]
    }
   ],
   "source": [
    "print(manual_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c507a39-5e43-4069-b4eb-3fd76ccf46ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[*] appName=PySparkShell>\n"
     ]
    }
   ],
   "source": [
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68174f75-438b-4421-8197-9d97bb035e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7fafc141d5b0>\n"
     ]
    }
   ],
   "source": [
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2566c5bf-e04a-4287-bda9-833353352e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "manual_schema_2 = StructType([StructField(\"Name\",StringType(), True), StructField(\"Age\",IntegerType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d98f68ff-08fe-4c59-a4cb-a40f54026da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(Name,StringType,true),StructField(Age,StringType,true)))\n"
     ]
    }
   ],
   "source": [
    "print(manual_schema_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e26e2420-565b-4883-822c-c7a443a76afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "myRow = Row(\"Tom\", 21)\n",
    "mydf = spark.createDataFrame([myRow], manual_schema_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d853906-ac73-4fb6-a1ec-7c120d40e2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|Name|Age|\n",
      "+----+---+\n",
      "| Tom| 21|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mydf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72672a8f-4aae-4840-8dbb-2b5dafbb23d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
